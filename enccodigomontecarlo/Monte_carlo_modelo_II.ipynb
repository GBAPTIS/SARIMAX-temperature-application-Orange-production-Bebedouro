{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'maximum_temperature.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m---> 11\u001b[0m max_temp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximum_temperature.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m min_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_temperature.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m max_temp\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'maximum_temperature.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Import Libraries and Load Raw Dato\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt \n",
    "max_temp = pd.read_csv('maximum_temperature.csv')\n",
    "min_temp = pd.read_csv('minimum_temperature.csv')\n",
    "max_temp.head()\n",
    "\n",
    "#Clean dat of Null Vaues and Show it is quantity\n",
    "max_temp.isnull().value_counts(),min_temp.isna().value_counts\n",
    "count = 0\n",
    "for mx, mn in zip(np.where(max_temp.isnull())[0], np.where(min_temp.isnull())[0]):\n",
    "    if mx != mn:\n",
    "        count +=1\n",
    "print('Number of Null Values: ', count)\n",
    "\n",
    "\n",
    "#Fram raw Data, Extracts Date (Y-M-D) Maximum and Minimum Temperatures (Tmax, and Tmin) and calculate the Daily Average ( T=(Tmax+Tmin)/2)\n",
    "\n",
    "\n",
    "def datetime(row):\n",
    "    return dt.datetime(row.Year, row.Month, row.Day)\n",
    "max_temp['Date'] = max_temp.apply(datetime,axis=1)\n",
    "min_temp['Date'] = min_temp.apply(datetime,axis=1)\n",
    "max_temp.set_index('Date',inplace=True)\n",
    "min_temp.set_index('Date', inplace=True)\n",
    "\n",
    "#MDrops column with useless data, renames the columns left, and merges the data frames\n",
    "drop_cols =[0,1,2,3,4,6,7]\n",
    "max_temp.drop(max_temp.columns[drop_cols], axis=1, inplace=True)\n",
    "min_temp.drop(min_temp.columns[drop_cols], axis=1, inplace=True)\n",
    "max_temp.rename(columns={'Maximum temperature (Degree F)': 'Tmax'}, inplace=True)\n",
    "max_temp.rename(columns={'Minimum temperature (Degree F)': 'Tmin'}, inplace=True)\n",
    "temps = max_temp.merge(min_temp, how=' inner',left_on=['Date'],right_on=['Date'])\n",
    "#Calculates Daily Average droping null values.\n",
    "\n",
    "def avg_temp(row):\n",
    "    return (row.Tmax+row.Tmin)/2\n",
    "temps['T'] = temps.apply(avg_temp, axis=1)\n",
    "# drop na values here \n",
    "temps  = temps.dropna()\n",
    "#Divides temperature in seasons wih Summer between May and September and Winter between October and April\n",
    "temps_season = temps.copy(deep=True)\n",
    "temps_season['month'] = temps_season. index.month\n",
    "mask = (temps_season['month'] >5) & (temps['month'] <= 10)\n",
    "temps_season['winter'] = np.where(mask,1,0)\n",
    "temps_season['summer'] = np.where(temps_season['winter'] != 1,1,0)\n",
    "temps_season\n",
    "#Creates timeseries with $T_{\\max }$, $T_{m i n}$ and, Daily Average, and plots: All data, Last 14 years, and Histogram\n",
    "temps[:].plot(figsize=(8,6))\n",
    "plt.show()\n",
    "#Timeseries plot  - 14 year\n",
    "temps[-5000:].plot(figsize=(8,6))\n",
    "temps.Tmax.hist(bins=60, alpha=0.6, label ='Tmax')\n",
    "temps.Tmin.hist(bins=60, alpha=0.6, label ='Tmin')\n",
    "temps['T'].hist(bins=60, alpha=0.8, label ='T')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#Plots Histograms of summer and winter temperatures\n",
    "plt.figure(figsizw=(8,6))\n",
    "temps_season[temps_season['summer'] == 1]['T'].hist(bins=60, alpha=0.8, label='Summer')\n",
    "temps_season[temps_season['winter'] == 1]['T'].hist(bins=60, alpha=0.8, label='Winter')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#imports Q-Q plot, ADFuller, Seasonal Decompose, ACF, and P-ACF tools.\n",
    "from statsmodels.graphics.api import qqplot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa,ar_model import AutoReg, ar_select_order, AutoResults\n",
    "\n",
    "#Plots Rolling Mean over Annual Period (Red) and Rolling Variance over Anual period (Blue).\n",
    "temps.sort_index(inplace=True)\n",
    "Years=20\n",
    "temps['T'].rolling(window = 365*Years).mean().plot(figsize=(12,8), color=\"tab:red\", title=\"Rolling mean over annual periods\", label = 'Mean')\n",
    "temps['T'].rolling(window = 365*Years).var().plot(figsize=(12,8), color=\"tab:blue\", title=\"Rolling mean and variance over annual periods\", label = 'Variance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Apply decompose Seasonal to time series and plot, Data, Irend, Seasonal, and Residual \n",
    "decompose_result = seasonal_decompose(temps['T'], model ='additive', period=int(365), extrapolate_trend='freq')\n",
    "trend = decompose_result.trend\n",
    "seasonal = decompose_result.seasonal\n",
    "residual = decompose_result.resid\n",
    "#Visualise all Data, Trend, Seasonal, and Residuals\n",
    "decompose_result.plot()\n",
    "plt.show()\n",
    "#Visualise x-Years\n",
    "Years = 20\n",
    "years_examine = 365*Years\n",
    "fig, axs = plt.subplots(3, figsize=(8,6))\n",
    "fig.suptitle('Removed Trend and Seasonality')\n",
    "axs[0].plot(trend[~years_examine:])\n",
    "axs[1].plot(seasonal[~years_examine:])\n",
    "axs[1].set_ylim([-10,10])\n",
    "\n",
    "#Apply fitting models and calculate parameters with Residual Sum of Squares(RSS)\n",
    "#Model 1 fit = a+bt+asin(wt+Lambda) here y_pred = a+bt+a1sin((omega)x +b1)\n",
    "#Model 2 fit = a+bt+asin(wt+Lambda)+Lambdacos(omega*t +phi) here y_pred=a+bt+a1sin((omega)x+theta)+b1cos((omega)x+phi)\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import check_fit\n",
    "temp_t = temps['T'].copy(deep=True)\n",
    "#Define Models\n",
    "# Model 1 (Sine)\n",
    "def model_fit(x, a b, a1, b1):\n",
    "     omega = 2 np.pi/365.25\n",
    "     y_pred = a +b*x + a1*np.cos(omega*x) + b1*np.sin(omega*x)\n",
    "     return y_pred\n",
    "def RSS(y, y_pred):\n",
    "    return np.sqrt( (y - y_pred)**2 ).sum()\n",
    "#Model 2(Generalized)\n",
    "def model_fit_general(x, a, b, a1, b1, theta, phi):\n",
    "    omega = 2*np.pi/365.25\n",
    "    y_pred = a + b*x + a1*np.cos(omega*x + theta) + b1*np.sin(omega*x + phi)\n",
    "return y_pred\n",
    "\n",
    "if isinstance(temp_t.index, pd.DatetimeIndex):\n",
    "    first_ord = temp_t.index.map(dt.datetime.toordinal)[0]\n",
    "    temp_t.index=temp_t.index.map(dt.datetime.toordinal)\n",
    "\n",
    "params, cov = curve_fit(model_fit, xdata = temp_t.index-first_ord, ydata = temp_t['T'], method='lm')\n",
    "param_list = ['a', 'b', 'a1', 'b1']\n",
    "print('\\n       Model 1 Parameters \\\\n')\n",
    "std_dev = np.sqrt(np.diag(cov))\n",
    "for name, p, sd in zip( param_list, params, std_dev):\n",
    "    print('{0} : {1:0.3} CI ~normally [{2:0.2e}, {3:0.2e}]'.format(name, p, p-1.96*sd, p+1.96*sd))\n",
    "temp_t['Model 1 (Sine)'] = model_fit(temp_t.index-first_ord, *params)\n",
    "if isinstance(temp_t.index, pd.DatetimeIndex):\n",
    "    temp_t.index=temp_t.index.map(dt.datetime,toordinal)\n",
    "params1, cov1 = curve_fit(model_fit_general, xdata = temp_t.index-first_ord, ydata = temp_t['T'], method='lm')\n",
    "param_list = ['a', 'b', 'a1', 'b1', 'theta', 'phi']\n",
    "print('\\n Model2 Paramerers \\n')\n",
    "std_dev = np.sqrt(np.diag(cov1))\n",
    "for name, p, sd in zip( param_list, params1, std_dev):\n",
    "    print(' {0} : {1:0.3} CI ~normally [{2:0.2e}, {3:0.2e}]'.format(name, p, p-1.96*sd, p+1.96*sd))\n",
    "temp_t['Model 2(Gen)'] = model_fit_general(temp_t.index-first_ord, *params1)\n",
    "if not isinstance(temp_t.index, pd.DatetimeIndex):\n",
    "    temp_t.index=temp_t.index.map(dt.datetime.fromordinal)\n",
    "temp_t[:2000].plot(figsize=(12,4), style=['s', '^-', 'k--'], markersize=4, linewidth=2 )\n",
    "temp_t[-2000:].plot(fugsize=(12,4), style=['s', '^-', 'k--'], markersize=4, linewidth=2  )   \n",
    "RSS(temp_t['T'], tem_t['Model 2 (Gen)'])\n",
    "print('\\n Residual Sum of Squares (RSS) \\n')\n",
    "print(' RSS Model 1 (Sine):', round (RSS(temp_t['T'], temp_t['Model 1 (Sine)']),2))\n",
    "print('  RSS Model 2 (Gen):', round(RSS(temp_t['T'], temp_t['Model 2 (Gen)']),2))\n",
    "\n",
    "#Calculate parameters with data and fit curve\n",
    "temp_t = temps['T'].copy(deep=True)\n",
    "temp_t = temp_t.to_frame()\n",
    "def model(x, params):\n",
    "    a,b,a1,b1 = params\n",
    "    omega = 2*np.pi/365.25\n",
    "    theta = np.arctan(a1/b1)\n",
    "    alpha = np.sqrt( a1**2 + b1**2)\n",
    "    print('Parameters:\\n     a{0:0.3}\\n   b{1:0.3}\\n alpha {2:0.3}\\n theta {3:0.3}'.format(a,b,alpha,theta))\n",
    "    y_pred = a + b*x + alpha*np.sin(omega*x + theta)\n",
    "    return y_pred\n",
    "\n",
    "def model_fit(x, a, b, a1, b1):\n",
    "        omega = 2*np.pi/365.25\n",
    "        y_pred = a + b*x + a1*np.cos(omega*x) + b1*np.sin(omega*x)\n",
    "        return y_pred\n",
    "if isinstance(temp_t.index , pd.DatetimeIndex):\n",
    "        first_ord = temp_t.index.map(dt.datetime.toordinal)[0]\n",
    "        temp_t.index=temp_t.index.map(dt.datetime.toordinal)\n",
    "params_all, cov = curve_fit(model_fit, xdata = temp_t.index-first_ord, ydata = temp_t['T'], method='lm' )\n",
    "\n",
    "temp_t['Model'] = model(temp_t.index-first_ord, params_all)\n",
    "if not isinstance(temp_t.index , pd.DatetimeIndex):\n",
    "     temp_t.index=temp_t.index.map(dt.datetime.fromordinal)\n",
    "temp_t[-2000:].plot(fifsize=(12,4), style=['s', '^-', 'k-'], markersize=4, linewidth=3 )\n",
    "plt.show()\n",
    "\n",
    "#Autocorrelation was applied and Residuals were analysed\n",
    "#Visualize Residuals after detrending and Removing seasonality from the Daily Average Temperature (DAT) 12 years\n",
    "if not isinstance(temp_t.index , pd.DatetimeIndex):\n",
    "     temp_t.index=temp_t.index.map(dt.datetime.fromordinal)\n",
    "temp_t['res'] = temp_t['T']-temp_t['Model']\n",
    "temp_t['res'][-5000:].plot(figsize=(12,6))\n",
    "plt.show()\n",
    "#visualizes autocorrelation for all the time series (Tlags) and the Last few years(PLags)\n",
    "Tlags = 30\n",
    "Plags = 30\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,8))\n",
    "fig.suptitle('Residuals after de-trending and removing seasonality from the DAT')\n",
    "axs[0,0].plot(temp_t['res'])\n",
    "axs[1,0].plot(temp_t['res'][-2000:])\n",
    "plot_acf(temp_t['res'], lags = TLags, ax=axs[0,1])\n",
    "plot_pacf(temp_t['res'], lags = Plags, ax=axs[1,1])\n",
    "plt.show()\n",
    "#Probablility distribution was Calculated and plotted\n",
    "stats.probplot(temp_t['res'], dist =\"norm\", plot=plt)\n",
    "plt.title(\"Normal Probability Plot\")\n",
    "plt.show()\n",
    "#Plot probability distribution of temperature errors and compares it to normal distribution.\n",
    "mu, std =norm.fit(temp_t['res'])\n",
    "z = (temp_t['res'] - mu)/std\n",
    "plt.hist(temp_t['res'], density=True, alpha=0.6, bins=100, label='Temp Error')\n",
    "xmin, xmax = plt.xlim()\n",
    "ymin, ymax = plt.ylim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "data = np.random.randn(100000)\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Normal Dist')\n",
    "plt.plot([std*2,std*2], [0,ymax])\n",
    "print('P(Z > 2): {:0.3}% vs. Normal Distribution: {:0.3}% '.format(len(z[z >= 2])/len(z)*100, (1-norm.cdf(2))*100))\n",
    "print('Skew    : {:0.3}'.format(stats.skew(z)))\n",
    "print('Kurtosis    : {:0.3}'.format(stats.kurtosis(z)+3))\n",
    "plt.ylabel('Probability Density')\n",
    "plt.xlabel('Temperature Errors')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Visualization of Fitted Data\n",
    "#plots Partial Data and Fit Model\n",
    "rows=2000\n",
    "temp_t [['T', 'Model']][-rows:].plot(figsize=(12,6), style=['s', 'k-'], markersize=4, linewidth=3 )\n",
    "plt.show()\n",
    "#Autoregression was applied to Temperature Residuals\n",
    "#Performs as Autoregression of the Residuals and print parameters\n",
    "residuals = temp_t['res']\n",
    "resiaduals.index = pd.DatetimeIndex(residuals.index).to_period('D')\n",
    "model = AutoReg(residuals, lags=1, old_names=True, trends='n')\n",
    "model_fit = model.fit()\n",
    "coef = model_fit.params\n",
    "res = model_fit.resid\n",
    "res.index = res.index.to_timestamp()\n",
    "print(model_fit.summary())\n",
    "\n",
    "#The monthly volatility of the DAT was estimated and Plot\n",
    "#Estimate volatility based on quadratic variation of temperature process. Plot Monthly Volatility of DAT\n",
    "temp_t['Day'] = temp_t.index.dayofyear\n",
    "temp_t['month'] = temp_t.index.month\n",
    "temp_t['year'] = temp_t.index.year\n",
    "vol = temp_t.groupby(['year', 'month'])['T'].agg(['mean', 'std'])\n",
    "vol = vol.reset_index()\n",
    "vol['std'].plot(figsize=(8,6))\n",
    "plt.plot([0, len(vol)], [vol['std'].mean(),vol['std'].mean()], 'k', linewidth=2)\n",
    "plt.ylabel('Std Dev (deg F)')\n",
    "plt.tittle('Monthly Volatility of Observed Daily Average Temperature', color='k')\n",
    "print('Trend or long Term volatility is easy: ~', round(vol['std'].mean(),3))\n",
    "plt.show()\n",
    "# The dailay volatity of DATA was estimated and Plotted\n",
    "#Estimate Daily Volatilty of DAT, and Plot\n",
    "vol =  temp_t.groupby(['Day'])['T'].agg(['mean', 'std'])\n",
    "vol['std'].plot(color='tab:blue', figsize=(8,6))\n",
    "plt.ylabel('Std Dev (deg F)', color= 'tab:blue')\n",
    "plt.xlim(0,364)\n",
    "plt.show()\n",
    "\n",
    "#Plot Spline Fit of Volatility\n",
    "from scipy import interpolate\n",
    "x= np.array(vol['std'].index)\n",
    "y = np.array(vol['std'].index)\n",
    "knot_numbers = 5\n",
    "x_new = np.linspace(0, 1, knot_numbers+2)[1:-1]\n",
    "q_knots = np.quantile(x, x_new)\n",
    "t,c,k = interpolate.splrep(x, y, t=q_knots, s=1)\n",
    "yfit = interpolate.BSpline(t,c,k)(x)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x, y, label='Volatility')\n",
    "plt.plot(x, yfit, label='Spline fit')\n",
    "plt.ylabel('Std Dev (deg C)')\n",
    "plt.xlabel('Day in Year')\n",
    "plt.xlim(0,364)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "def spline(knots, x, y):\n",
    "     x_new = np.linspace(0, 1, knots+2)[1:-1]\n",
    "     t, c, k = interpolate.splrep(x, y, t=np.quantile(x, x_new), s=3)\n",
    "     yfit = interpolate.BSpline(t,c, k)(x)\n",
    "     return yfit\n",
    "\n",
    "knots = [3, 10, 20,30, 50, 80]\n",
    "i = 0\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(8, 5))\n",
    "for row in range(2):\n",
    "     for col in range(3):\n",
    "          ax[row][col].plot(x, y, '.',c='tab:orange', markersize =4)\n",
    "          yfit = spline(knots[i], x ,y)\n",
    "          rss = np.sum( np.square(y-yfit) )\n",
    "          ax[row][col].plot(x, yfit, 'k', linewidth=2)\n",
    "          ax[row][col].set_title(\"Knots Pi\" + str(knots[i])+ \"\\nRSS: \" +str(round(rss,2)), color='k')\n",
    "          ax[row][col].set_xlim(0,366)\n",
    "          ax[row][col].grid()\n",
    "          i=i+1\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#estimate Volatility from the quadratic Variation of the Temperature Process\n",
    "temp_vol = temps['T'].copy(deep=True)\n",
    "temp_vol = temp_vol.to_frame()\n",
    "temp_vol['Day'] = temp_vol.index.dayofyear\n",
    "temp_vol['month'] = temp_vol.index.month\n",
    "vol = temp_vol.groupby(['Day'])['T'].agg(['mean', 'std'])\n",
    "days = np.array(vol['std'].index)\n",
    "T_std = np.array(vol['std'].values)\n",
    "#fits STd DEV to 5-knots spline\n",
    "def spline(knots, x, y):\n",
    "     x_new = np.linspace(0, 1, knots+2)[1:-1]\n",
    "     t, c, k = interpolate.splrep(x, y, t=np.quantile(x, x_new), s=3)\n",
    "     yfit = interpolate.BSpline(t,c, k)(x)\n",
    "     return yfit\n",
    "volatility = spline(5, days, T_std)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(days, T_std, marker='.', label='Volatility')\n",
    "plt.plot(days, volatility, linewidth=4, label='Spline fit')\n",
    "plt.ylabel('Std Dev (deg F)')\n",
    "plt.xlabel('Day in Year')\n",
    "plt.xlim(0,364)\n",
    "plt.legend(loc='Lower right')\n",
    "plt.show()\n",
    "\n",
    "#Estimate volatility of the volatility process by using the quadratic variation of sigma\n",
    "print('Gamma is : ', round(vol['std'].std(),3))\n",
    "model = AutoReg(vol['std'], lags=1, old_names=Truem trend='n')\n",
    "model_fit = model.fit()\n",
    "coef = model_fit.params\n",
    "res = model_fit.resid\n",
    "print('Rate of mean reversion of volatility process is    : ', coef[0])\n",
    "print(model_fit.summary())\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "#####\n",
    "#Apply Euler approximation to Time Series\n",
    "def euler_step(row, kappa, M):\n",
    "    #*** Function for Euler sheme approximation step in\n",
    "    #midified OH Dynamics for temperature simulations\n",
    "    #inputs:\n",
    "    #dataframe row with columns: T, Tbar, dTbar and vol\n",
    "    #kappa: rate of mean reversion from data processing code\n",
    "    #Output:\n",
    "    # temp:simulated next day temperature\n",
    "    if row['Tbar_shift'] != np.nan:\n",
    "        T_i = row['Tbar']\n",
    "    else:\n",
    "        T_i = row['Tbar_shift']\n",
    "    T_det = T_i + row['dTbar']\n",
    "    T_mrev = kappa*(row['Tbar'] - T_i)\n",
    "    sigma = row['vol']*np.random.randn(M)\n",
    "    #riskn = lamda*row['vol']\n",
    "    return T_det + T_mrev + sigma\n",
    "\n",
    "#Apply Monte Carlo approximation to time series\n",
    "def monte_carlo_temp(trading_dates, Tbar_params, vol_model, first_ord, M=1, kappa=0.438):\n",
    "    #Monte Carlo simulation of temperature\n",
    "    #Inputs:\n",
    "    #trading_dates: pandas DatetimeIndex from start to end dates\n",
    "    #M:number of simulations\n",
    "    #Tbar_params:parameters used for Tbar model\n",
    "    #vol_model: fitted volatility model with days in year index\n",
    "    #first_ord: first ordinal of fitted Tbar model\n",
    "    # Output:\n",
    "    # mc_temps: DataFrame of all components and simulated temperatures\n",
    "    kappa=0.438\n",
    "    if isinstance(trading_dates, pd.DatetimeIndex):\n",
    "        trading_date=trading_dates.map(dt.datetime.toordinal)\n",
    "\n",
    "    #Use Modified Ornstein-Uhlenbeck process with estimated parameters to stimulate Tbar DAT\n",
    "    Tbars = T_model(trading_date-first_ord, *Tbar_params)\n",
    "    #Use derivative of modified OH process SDE to calculate change of Tbar \n",
    "    dTbars = dT_model(trading_date-first_ord, *Tbar_params)\n",
    "    \n",
    "\n",
    "    mc_temps = pd.DataFrame(data=np.array([Tbars, dTbars]).T, index=trading_dates, columns=['Tbar', 'dTbar'])\n",
    "    mc_temps['day'] = mc_temps.index.dayofyear\n",
    "    mc_temps['vol'] =vol_model[mc_temps['day']-1]\n",
    "\n",
    "    mc_temps['T'] =mc_temps['Tbar'].shift(1)\n",
    "    data = mc_temps.apply(euler_step, args=[kappa, M], axis=1)\n",
    "    mc_sims = pd.DataFrame(data=[x for x in [y for y in data.values]], index=trading_dates, columns=range(1, M+1))\n",
    "    return mc_temps, mc_sims\n",
    "\n",
    "#Ornstein -Uhlenbeck process with Modified OU Stochastic Diff Eq. and parameters a, b alpha,theta.\n",
    "if isinstance(temp_t.index , pd.DatetimeIndex):\n",
    "     first_ord = temp_t.index.map(dt.datetime.toordinal)[0]\n",
    "     temp_t.index=temp_t.index.map(dt.datetime.toordinal)\n",
    "#Define T\n",
    "def dT_model(x, a, b, alpha, theta):\n",
    "     omega=2*np.pi/365.25\n",
    "     dT = b + alpha*omega*np.cos(omega*x + theta)\n",
    "     return dT\n",
    "#input parametes and plot model \n",
    "Tbar_params = [62.1, 6.08e-05, 9.03, 1.26]\n",
    "temp_t['model_fit'] = T_model(temp_t.index-first_ord, *Tbar_params)\n",
    "if not isinstance(temp_t.index , pd.DatetimeIndex):\n",
    "    temp_t.index=temp_t.index.map(dt.datetime.fromordinal)\n",
    "\n",
    "# define trading date range\n",
    "no_sims = 5\n",
    "trading_dates = pd.date_range(start='2024-04-22', end='2025-04-22', freq='D')\n",
    "mc_temps, mc_sims = monte_carlo_temp(trading_dates, Tbar_params, volatility, first_ord, no_sims)\n",
    "\n",
    "mc_temps\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "mc_sims[1].plot(alpha=0.6, linewidth=2, marker='.')\n",
    "mc_temps[\"Tbar\"].plot(linewidth=4)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "no_sims = 10000\n",
    "trading_dates_winter = pd.date_range(start='2023-07-01', end='2023-07-01', freq='D')\n",
    "mc_temps_winter, mc_sims_winter = monte_carlo_temp(trading_dates_winter, Tbar_params, volatility, first_ord, no_sims)\n",
    "trading_dates_summer = pd.date_range(start='2023-01-01', end='2023-01-01', freq='D')\n",
    "mc_temps_summer, mc_sims_summer = monte_carlo_temp(trading_dates_summmer, Tbar_params, volatility, first_ord, no_sims)\n",
    "plt.fugure(figsize=(12,6))\n",
    "plt.title('Winter vs Summer Temperature MC Sims')\n",
    "Tbar_summer = mc_temps_summer.iloc[-1,:]['Tbar']\n",
    "Tbar_winter = mc_temps_summer.iloc[-1,:]['Tbar']\n",
    "plt.hist(mc_sins_summer.iloc[-1,:],bins=20, alpha=0.5, label='Summer', color='tab:orange')\n",
    "plt.plot([Tbar_summer, Tbar_summer],[0,1600], linewidth=4, lable='Tbar_summer',  color='tab:orange')\n",
    "plt.title('Summer vs Winter Temperature MC Sims')\n",
    "plt.hist(mc_sims_winter.iloc[-1,:],bins=20, alpha=0.5, label='Winter', color='tab:blue')\n",
    "plt.plot([Tbar_winter, Tbar_winter],[0,1600], linewidth=4, lable='Tbar_winter',  color='tab:blue')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "              \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
